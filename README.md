# Choice2Vec: Self-Supervised Learning for Behavioral Data

A comprehensive framework for self-supervised learning on behavioral data, featuring multiple approaches and extensive analysis tools.

## ğŸ—ï¸ Project Structure

```
Choice2Vec/
â”œâ”€â”€ core/                           # Core model implementations
â”‚   â”œâ”€â”€ choice2vec_model.py        # Base Choice2Vec model and trainer
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data_generation/                # Data generation scripts
â”‚   â”œâ”€â”€ generate_data.py           # Basic behavioral data generation
â”‚   â”œâ”€â”€ generate_psychological_data.py  # Enhanced psychological data
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ standard_choice2vec/            # Standard Choice2Vec approach
â”‚   â”œâ”€â”€ train_choice2vec.py        # Main training script
â”‚   â”œâ”€â”€ unsupervised_classification.py  # Alternative training approach
â”‚   â”œâ”€â”€ compare_losses.py          # Loss function comparisons
â”‚   â”œâ”€â”€ test_convergence.py        # Convergence analysis
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ disentangled_choice2vec/        # Disentangled representation learning
â”‚   â”œâ”€â”€ disentangled_choice2vec.py # Disentangled model implementation
â”‚   â”œâ”€â”€ train_disentangled_choice2vec.py  # Training and comparison
â”‚   â”œâ”€â”€ test_disentanglement.py    # Quick testing script
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ checkpoints/                    # Long-term training with checkpoints
â”‚   â”œâ”€â”€ psychological_unsupervised_classification.py  # 150k epoch training
â”‚   â”œâ”€â”€ analyze_checkpoints.py     # Checkpoint analysis tools
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ evaluation/                     # Model evaluation and analysis
â”‚   â”œâ”€â”€ evaluate_saved_model.py    # Load and evaluate saved models
â”‚   â”œâ”€â”€ list_models.py             # List available models
â”‚   â”œâ”€â”€ analyze_learning_curves.py # Learning curve analysis
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/                          # Utility functions (future)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ README.md                  # Main documentation (this file)
â”‚   â”œâ”€â”€ DISENTANGLEMENT_README.md  # Disentanglement techniques guide
â”‚   â””â”€â”€ CHECKPOINT_README.md       # Checkpoint system guide
â”œâ”€â”€ results/                        # Generated data and plots
â”‚   â”œâ”€â”€ *.csv                      # Generated datasets
â”‚   â”œâ”€â”€ *.png                      # Generated visualizations
â”‚   â””â”€â”€ *.pkl                      # Saved models
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Quick Start

### 1. Generate Data
```bash
# Basic behavioral data (2,500 trials)
python data_generation/generate_data.py

# Enhanced psychological data (12,500 trials)
python data_generation/generate_psychological_data.py
```

### 2. Train Models

#### Standard Choice2Vec
```bash
# Quick training (1000 epochs)
python standard_choice2vec/train_choice2vec.py

# Compare different loss functions
python standard_choice2vec/compare_losses.py
```

#### Disentangled Choice2Vec
```bash
# Test implementation
python disentangled_choice2vec/test_disentanglement.py

# Full comparison training
python disentangled_choice2vec/train_disentangled_choice2vec.py
```

#### Long-term Training with Checkpoints
```bash
# 150,000 epoch training with automatic checkpoints
python checkpoints/psychological_unsupervised_classification.py
```

### 3. Evaluate Models
```bash
# List available saved models
python evaluation/list_models.py

# Evaluate a specific model
python evaluation/evaluate_saved_model.py

# Analyze learning curves
python evaluation/analyze_learning_curves.py
```

## ğŸ“Š Approaches Implemented

### 1. **Standard Choice2Vec** (`standard_choice2vec/`)
- Base wav2vec 2.0 adaptation for behavioral data
- InfoNCE contrastive learning
- Selective masking strategy
- Multiple loss function variants

**Key Features:**
- 3.9M parameters
- Transformer-based architecture
- Product quantization
- Achieves ~84% psychological state classification

### 2. **Disentangled Choice2Vec** (`disentangled_choice2vec/`)
- Enhanced with disentanglement techniques
- Î²-VAE style regularization
- Mutual information minimization
- Orthogonality constraints
- Factor-wise contrastive learning

**Key Features:**
- Addresses entangled representations (10+ PCs â†’ 3-5 PCs for 95% variance)
- 4 quantizer groups for finer factorization
- Multiple disentanglement loss terms
- Comprehensive analysis tools

### 3. **Checkpoint System** (`checkpoints/`)
- Long-term training (150,000 epochs)
- Automatic checkpointing every 10,000 epochs
- Comprehensive analysis at each checkpoint
- Multiple clustering algorithms
- Extensive visualization generation

**Key Features:**
- Saves model weights, representations, and clustering results
- Automatic PCA, t-SNE, and clustering analysis
- 4-row visualization plots
- Cross-device compatible saving

## ğŸ”§ Installation

```bash
# Create conda environment
conda create -n choice2vec python=3.9
conda activate choice2vec

# Install dependencies
pip install jax[cuda] flax optax pandas numpy matplotlib seaborn scikit-learn

# For CPU-only (if no GPU)
pip install jax[cpu] flax optax pandas numpy matplotlib seaborn scikit-learn
```

## ğŸ“– Documentation

- **[Main Documentation](docs/README.md)**: Complete technical documentation
- **[Disentanglement Guide](docs/DISENTANGLEMENT_README.md)**: Disentanglement techniques and theory
- **[Checkpoint Guide](docs/CHECKPOINT_README.md)**: Long-term training system

## ğŸ¯ Key Results

### Standard Choice2Vec
- **Accuracy**: 83.8% psychological state classification
- **Training**: Converges in ~1000 epochs
- **Architecture**: 3.9M parameters, 4 transformer layers

### Disentangled Choice2Vec
- **PCA Efficiency**: Reduces components needed for 95% variance from 10+ to 3-5
- **Factor Independence**: Mean correlation between factors < 0.3
- **Interpretability**: Each factor captures distinct behavioral aspects

### Long-term Training
- **Duration**: 150,000 epochs with checkpoints
- **Analysis**: Comprehensive clustering and representation analysis
- **Visualization**: Automatic generation of analysis plots

## ğŸ”¬ Research Applications

- **Cognitive Science**: Understanding decision-making processes
- **Psychology**: Modeling attention and engagement states
- **Human-Computer Interaction**: Adaptive interfaces based on user state
- **Neuroscience**: Computational models of behavioral patterns

## ğŸ¤ Contributing

The codebase is organized for easy extension:

1. **New Models**: Add to appropriate folder with consistent API
2. **New Analysis**: Add to `evaluation/` folder
3. **New Data**: Add generators to `data_generation/`
4. **Documentation**: Update relevant README files

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

Based on wav2vec 2.0 principles adapted for behavioral data analysis. Incorporates techniques from Î²-VAE, Factor-VAE, and contrastive learning literature. 